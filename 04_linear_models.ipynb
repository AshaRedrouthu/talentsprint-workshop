{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.fftpack import dct, idct\n",
    "import utils\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression, Lasso\n",
    "plt.style.use('ggplot')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Models in Classification\n",
    "<h1><p style=\"text-align: center;\">$$ \\hat{\\mathbf{y}} = f(\\sum_{i=1}^{m}x_{i}w_{i} + b) = f(\\mathbf{x^{T}w} + b)$$ </p></h1>\n",
    "## Where:\n",
    "<h2><p style=\"text-align: center;\">$m$ = number of training samples</p></h2>\n",
    "<h2><p style=\"text-align: center;\">$\\mathbf{x}$ = vector containing input features</p></h2>\n",
    "<h2><p style=\"text-align: center;\">$\\mathbf{w}$ = vector of weights (or coefficients)</p></h2>\n",
    "<h2><p style=\"text-align: center;\">$b$ = bias</p></h2>\n",
    "<h2><p style=\"text-align: center;\">$f$ is some thresholding function</p></h2>\n",
    "\n",
    "## Typically:\n",
    "<h2><p style=\"text-align: center;\">$\n",
    "    f(x)= \n",
    "\\begin{cases}\n",
    "    1,& \\text{if } x > 0\\\\\n",
    "    0,              & x \\leq 0\n",
    "\\end{cases}\n",
    "$</p></h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = utils.make_classification()\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression()\n",
    "lr.fit(X, y)\n",
    "plt.figure(figsize=(8, 6))\n",
    "utils.draw_decision_boundary(lr, X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise: Try fitting the logistic regression model on the following dataset and plot the decision boundary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = utils.make_moons(noise=0.01)\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# enter code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question: What went wrong?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "svc = SVC()\n",
    "svc.fit(X, y)\n",
    "utils.draw_decision_boundary(svc, X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise: Try to fit a SVC to the following dataset and plot the decision boundary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = utils.make_circles(factor=0.1, noise=0.1)\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# enter code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Models in Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<h1><p style=\"text-align: center;\">$$ \\hat{\\mathbf{y}} = \\sum_{i=1}^{m}\\beta_{i}x_{i} + \\epsilon = \\mathbf{x^T\\beta} + \\epsilon$$ </p></h1>\n",
    "## Where:\n",
    "<h2><p style=\"text-align: center;\">$m$ = number of training samples</p></h2>\n",
    "<h2><p style=\"text-align: center;\">$\\mathbf{x}$ = vector containing input features</p></h2>\n",
    "<h2><p style=\"text-align: center;\">$\\mathbf{\\beta}$ = vector of coefficients</p></h2>\n",
    "<h2><p style=\"text-align: center;\">$\\epsilon$ = error, residue or nouse</p></h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(100)\n",
    "y = np.linspace(0, 1, 100) + np.random.rand(100,) * 0.1\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(x, y)\n",
    "plt.xlabel('$x$')\n",
    "plt.ylabel('$y$')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LinearRegression()\n",
    "lr.fit(x.reshape(-1, 1), y)\n",
    "y_hat = lr.predict(x.reshape(-1, 1))\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(x, y, label='original')\n",
    "plt.plot(x, y_hat, 'g', label='predicted')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examining the coefficients of the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat_unfit = x * lr.coef_ + lr.intercept_\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(x, y_hat, 'go', x, y_hat_unfit, 'r-')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise: Fit a linear model to the following dataset and find its slope and intercept."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = utils.make_regression_exercise()\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(X, y)\n",
    "plt.xticks([])\n",
    "plt.yticks([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# enter code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Examine the source code of `utils.make_regression_exercise` to check answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sparsity in Linear Models and Data Compression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All regression is approximation, solving\n",
    "<h2><p style=\"text-align: center;\">$$ Ax = b $$</p></h2>\n",
    "\n",
    "## Where:\n",
    "\n",
    "<h2><p style=\"text-align: center;\">$$ A \\in \\mathbb{R}^{m \\times n} $$</p></h2>\n",
    "\n",
    "## When\n",
    "\n",
    "<h2><p style=\"text-align: center;\">$m > n$, $A$ is a tall matrix ðŸ¡’ overdetermined system of equations</p></h2>\n",
    "<h2><p style=\"text-align: center;\">$m < n$, $A$ is a fat matrix ðŸ¡’ underdetermined system of equations</p></h2>\n",
    "\n",
    "## An overdetermined system has no solution ðŸ¡’ solve an approximation\n",
    "### For example, find a solution that produces the least MSE, i.e.\n",
    "<h2><p style=\"text-align: center;\">$$ \\underset{x}{min}\\|Ax - b\\|^2 $$</p></h2>\n",
    "## An underdetermined system has infinitely many solutions ðŸ¡’ impose a constraint on solutions\n",
    "### For example, find the _sparsest_ solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example: The Simplest Impossible Problem\n",
    "## Which two numbers have the mean 3?\n",
    "\n",
    "## Arithmetic mean as matrix multiplication:\n",
    "\n",
    "$ A = \\begin{bmatrix}\n",
    "0.5 & 0.5 \\\\\n",
    "0 & 0\n",
    "\\end{bmatrix}$\n",
    "\n",
    "$b = \\begin{bmatrix}\n",
    "3\\\\\n",
    "0\n",
    "\\end{bmatrix} $\n",
    "\n",
    "\n",
    "$x = \\begin{bmatrix}\n",
    "x_{1}\\\\\n",
    "x_{2}\n",
    "\\end{bmatrix}$\n",
    "\n",
    "## Then solve\n",
    "$Ax = b$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.array([[0.5, 0.5], [0, 0]])\n",
    "b = np.array([[3], [0]])\n",
    "lr.fit(A, b)  # Linear Regression\n",
    "print(lr.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso = Lasso(alpha=0.0001)\n",
    "lasso.fit(A, b)\n",
    "print(lasso.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example: DTMF - Linear Combination of Two Sinusoids\n",
    "![](dtmf.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Fs = 32768\n",
    "duration = 0.25\n",
    "t = np.linspace(0, duration, duration * Fs)\n",
    "f1, f2 = 697, 1336\n",
    "y1 = np.sin(2 * np.pi * f1 * t);\n",
    "y2 = np.sin(2 * np.pi * f2 * t);\n",
    "y = (y1 + y2) / 2\n",
    "plt.plot(t, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Audio\n",
    "Audio(y, rate=44100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Repeat the signal ten times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = np.linspace(0, duration * 10, duration * 10 * Fs)\n",
    "f1, f2 = 697, 1336\n",
    "y1 = np.sin(2 * np.pi * f1 * t);\n",
    "y2 = np.sin(2 * np.pi * f2 * t);\n",
    "y = (y1 + y2) / 2\n",
    "Audio(y, rate=44100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recreate the original signal for simplicity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = np.linspace(0, duration , duration * Fs)\n",
    "f1, f2 = 697, 1336\n",
    "y1 = np.sin(2 * np.pi * f1 * t);\n",
    "y2 = np.sin(2 * np.pi * f2 * t);\n",
    "y = (y1 + y2) / 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Randomly sampling the signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = y.shape[0]  # length of the signal\n",
    "M = 800  # number of samples\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.subplot(211), plt.plot(t, y)\n",
    "plt.xlim(0, 0.125)\n",
    "plt.title('Original Signal')\n",
    "# Randomly sampling the test signal\n",
    "k = np.random.randint(0, N, (M,))\n",
    "k = np.sort(k) # making sure the random samples are monotonic\n",
    "b = y[k]\n",
    "plt.subplot(212), plt.plot(t, y, 'b', t[k],b,'r.')\n",
    "plt.xlim(0, 0.125)\n",
    "plt.title('Original Signal with Random Samples')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discrete Cosine Coefficients as the data that \"predict\" the signal\n",
    "### Or, which signal, when operated on by a DCT, will produce the sampled signal?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = dct(np.eye(N), axis=0)\n",
    "A = D[k,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso = Lasso(alpha=0.001)\n",
    "lasso.fit(A, b)\n",
    "print(lasso.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Sparsity {} %'.format((lasso.coef_ != 0).sum() / lasso.coef_.shape[0] * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "recons = idct(lasso.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 8))\n",
    "plt.subplot(211), plt.plot(recons)\n",
    "plt.title('Reconstructed signal')\n",
    "plt.subplot(212), plt.plot(np.linspace(0, Fs / 2, N), lasso.coef_), plt.xlim(0, 2500)\n",
    "plt.title('Sparse Coefficients')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Thresholding the coefficients:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coefs = lasso.coef_.copy()\n",
    "coefs[np.abs(coefs) <= 0.1] = 0\n",
    "recons_th = idct(coefs)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.subplot(211), plt.plot(recons_th)\n",
    "plt.title('Reconstructed signal')\n",
    "plt.subplot(212), plt.plot(np.linspace(0, Fs /2, N), coefs), plt.xlim(0, 2500)\n",
    "plt.title('Sparse Coefficients (Thresholded)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(np.tile(recons_th, 10),  rate=44100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
